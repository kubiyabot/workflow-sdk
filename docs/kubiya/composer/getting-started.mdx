---
title: "Getting started with Kubiya Composer"
description: "Step‑by‑step guide to launching the Composer and creating your first AI‑powered workflow"
icon: "play"
---

# Getting started with Kubiya Composer

This guide walks you through accessing the Composer UI, connecting an agent server and running your first workflow.  If you're looking for an architectural overview of how the system works, see [Kubiya Composer](/composer/overview).

## Access the Composer UI

1. **Navigate to the Composer** – Visit `compose.kubiya.ai` in your browser.  The Composer is currently in public beta; you’ll need a Kubiya account to sign in.
2. **Sign in or sign up** – Click **Sign in** and authenticate with the provider of your choice (GitHub, Google or email).  If you don’t yet have a Kubiya account, choose **Sign up** and follow the prompts.  During the beta you may be asked to request access; Kubiya will notify you when your account is enabled.
3. **Authorize API keys** – After logging in, go to **Settings → API Keys**.  Create an API key for the Kubiya Agent Server and optionally provide API keys for your preferred LLM providers (OpenAI, Anthropic, Groq, etc.).  The Composer uses these keys to call agents on your behalf.

> **Tip:** To use the Composer locally (e.g. when running the `composer-ui` repo in development), set your API keys in a `.env.local` file as described in the repository `README`【951522503852125†L60-L119】.

## Describe a task

Once you’re signed in, the home page displays a **task input** field.  Simply describe what you want to accomplish in natural language.  For example:

```text
Create a simple API: use node:18‑alpine to create an Express server with a `/health` endpoint, then use alpine/curl to test it, and finally package it with node:18‑alpine for production
```

When you submit a request, the Composer forwards it to the agent server, which uses an LLM and the MCP toolchain to produce a workflow DSL.  The DSL is displayed in a panel so you can review and edit it.  The UI also shows a **visual DAG**, with each step represented as a node and dependencies drawn as edges【777760711526177†L232-L289】.

## Run and monitor the workflow

Click **Run** to execute the workflow.  Each step runs in its own container on the selected runner.  As the workflow executes, outputs stream back to the UI:

* **Logs** – Standard output and error from each container are shown in real time.  You can expand a node to view its full log and download it.
* **Artifacts** – Files generated by the workflow (e.g. reports, images) appear in the **Artifacts** panel.  Click an artifact to preview it; PDFs and PNGs render directly in the UI【240836907756966†L59-L74】.
* **Progress and status** – Nodes transition through states (queued, running, succeeded, failed).  Failed steps are highlighted; you can view errors and decide whether to retry or modify the DSL.

If a step fails due to a runtime exception, the error details are displayed along with a stack trace【240836907756966†L41-L55】.  Since each step is isolated, failures do not cascade—subsequent steps won’t run until dependencies succeed【777760711526177†L92-L116】.

## Use template prompts

For inspiration, the Composer offers a library of **suggested prompts**.  Click **Use a template** to view categories such as AI + DevOps, Web Development, Testing and Data Processing.  Selecting a template inserts a detailed prompt into the task input, showing which container images will be used.  Examples include:

| Category | Prompt summary |
|---------|----------------|
| **Intelligent incident response** | Detect anomalies with `datadog/agent:latest`, analyze logs via `langchain/langchain:latest`, apply a remediation with `kubectl:latest` and verify recovery with `alpine/curl`【691926627695274†L29-L40】 |
| **Static site builder** | Use `node:18‑alpine` to create HTML pages, minify them with `alpine:latest` and serve them via `busybox:latest`【691926627695274†L47-L53】 |
| **API test runner** | Test REST endpoints using `alpine/curl`, `python:3‑alpine` and `node:alpine`, generating a JSON test report【691926627695274†L56-L61】 |
| **ML feature engineering** | Extract data with `python:3‑alpine`, engineer features via a custom agent (`your‑org/feature‑agent:latest`), validate with `scikit‑learn/sklearn:latest` and version the dataset using `dvc:latest`【691926627695274†L65-L69】 |

Selecting a template is a great way to learn how workflow steps map to container images and to discover best practices for orchestrating AI agents and classic tools together.

## Configure runners and agents

Kubiya provides hosted runners that require zero setup.  If you need to access private resources or enforce custom security policies, you can register **self‑hosted runners**.  Visit **Settings → Runners** in the Composer to generate a runner token and follow the instructions to deploy the `kubiya-runner` container in your environment.  See the [Runners documentation](/concepts/runners) for details.

You can connect to your own **Agent Server** instead of using Kubiya’s hosted agents.  In the task input panel, click **LLM Provider** to choose your provider and specify the base URL.  Provide an API key for the server in the settings.  The Composer supports OpenAI‑compatible endpoints, so you can host agents using MCP or other frameworks【777760711526177†L294-L333】.

## Collaborate with your team

Invite colleagues to co‑edit workflows in real time.  When collaboration is enabled on a workflow, participants’ cursors are visible on the canvas and operations (adding or deleting nodes, editing DSL) sync instantly【860359785325647†L47-L107】.  Use the **Comments** sidebar to discuss particular nodes or sections of a conversation; comments can be resolved when addressed and filtered by status【679700562295946†L67-L183】.

## Next steps

You have created and executed your first workflow!  Explore the [Composer architecture](./architecture.mdx) to understand the components under the hood, or view [Example workflows](./examples.mdx) for more complex use cases.
