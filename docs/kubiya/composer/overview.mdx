---
title: "Kubiya Composer"
description: "Overview of Kubiya’s agentic UI for designing and executing AI‑powered workflows"
icon: "sparkles"
---

# Kubiya Composer

Kubiya Composer is an **agentic user interface** for building, visualizing and running AI‑powered workflows.  It bridges the gap between natural‑language instructions and deterministic execution by combining large‑language models with Kubiya’s workflow DSL and containerized runners.  The Composer is built on top of a modern frontend stack (Next.js 14 with the App Router, shadcn/ui and Tailwind CSS) and uses the E2B sandbox to execute AI‑generated code securely【951522503852125†L0-L7】.

## Why use Kubiya Composer?

 * **Turn ideas into workflows quickly.**  Describe a task in plain English and let the Composer generate a workflow in Kubiya’s DSL.  The system translates your request into an executable directed acyclic graph (DAG) and streams progress back to the UI in real‑time【777760711526177†L232-L289】.
 * **Deterministic execution.**  Unlike traditional agent chains where each run may follow a different path, Kubiya workflows are deterministic.  The same input produces the same set of containerized steps every time, making debugging and auditing straightforward【777760711526177†L92-L116】.
 * **Container isolation for each step.**  Each node in a workflow runs in its own container.  This isolates failures, prevents dependency conflicts and ensures reproducible results【777760711526177†L173-L179】.
 * **Rich ecosystem of stacks and LLMs.**  Kubiya Composer ships with interpreters for Python, Node/Next.js, Vue.js, Streamlit and Gradio, and supports multiple LLM providers including OpenAI, Anthropic, Google AI, Mistral, Groq, Fireworks, Together AI and Ollama【951522503852125†L9-L24】.  You can add your own interpreters or models by packaging them as Docker images.
 * **Streaming user interface.**  The UI displays logs, cell outputs, artifacts and intermediate results as they stream in.  You can inspect logs per step, view PDFs or images generated by the code and download artifacts for further analysis【240836907756966†L0-L74】.
 * **Real‑time collaboration.**  Multiple users can edit a workflow simultaneously, with presence indicators, cursor sharing and a comment sidebar.  Comments can be attached to specific nodes or ranges of text, resolved when addressed and filtered to show unresolved items【679700562295946†L67-L183】【860359785325647†L47-L107】.
 * **Secure execution with E2B sandbox.**  The Composer uses the [E2B SDK](https://github.com/e2b-dev/code-interpreter) to run AI‑generated code inside secure, disposable sandboxes.  This allows you to install packages from npm or pip and run arbitrary Python or Node code without compromising the host【951522503852125†L4-L8】.
 * **Extensible and observable.**  Built‑in telemetry forwards errors and performance metrics to Sentry.  Developers can instrument their own code with custom tracing functions (e.g. `trackLLMOperation`, `recordTokenUsage` and `trackModelCall`)【951522503852125†L130-L153】.

## Architecture overview

The Composer sits between the user and Kubiya’s underlying agent platform.  The high‑level flow looks like this【777760711526177†L186-L221】:

1. **Describe your task.** You enter a natural‑language request in the Composer UI such as “Build a simple API and test it.”
2. **Agent server translation.** The Composer forwards your prompt to a Kubiya Agent Server (OpenAI‑compatible) that uses LLMs and the MCP toolchain to generate a workflow DSL.  You can run the agent server yourself or use Kubiya‑hosted endpoints.
3. **DSL compilation.** The generated DSL is compiled into an executable DAG.  Dependencies between steps are automatically inferred and visualized【777760711526177†L232-L289】.
4. **Runner execution.** Each step of the DAG runs inside a container on a Kubiya runner.  Kubiya offers **hosted runners** for zero‑setup serverless execution and **self‑hosted runners** for running workflows within your own infrastructure【777760711526177†L382-L419】.
5. **Streaming feedback.** Step outputs stream back to the UI.  You can watch logs, see file artifacts, view images or PDFs and download results.

This architecture allows you to combine AI reasoning with deterministic, auditable execution in a single interface.  See the [Composer architecture](./architecture.mdx) page for a deeper dive.

## Supported stacks and models

The Composer includes built‑in runtime environments and language models.  Each environment corresponds to a Docker image used to execute steps.  You can bring your own interpreters by pushing custom images to a registry and referencing them in your DSL.

| Category | Examples |
|---------|---------|
| **Programming stacks** | Python (`python:3-alpine`), Node/Next.js (`node:alpine`, `node:18-alpine`), Vue.js, Streamlit, Gradio |
| **AI/ML agents** | LangGraph, CrewAI, custom agents packaged as Docker images【777760711526177†L337-L376】 |
| **LLM providers** | OpenAI, Anthropic, Google AI, Mistral, Groq, Fireworks, Together AI, Ollama【951522503852125†L15-L23】 |

You can also integrate infrastructure‑specific tools such as `kubectl`, `helm`, `jq`, `curl`, `grafana/k6`, `dvc` and more by specifying their container images in your workflow steps.

## Beta status and roadmap

Kubiya Composer is currently in **public beta**.  The limited preview provides full functionality for a small number of workflows.  Enterprise‑grade features such as unlimited workflows, custom agent integration, advanced security/compliance (SOC‑2, HIPAA) and SLA‑backed support are on the roadmap【777760711526177†L425-L483】.  Contact the Kubiya team if your organization would like early access to these capabilities.

Continue to [Get started](./getting-started.mdx) to learn how to launch the Composer and create your first workflow.
