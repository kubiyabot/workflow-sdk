---
title: "kubiya_inline_source"
sidebarTitle: "Inline Source Resource"
description: "Define tools and workflows directly in Terraform configuration"
icon: "code"
---

The `kubiya_inline_source` resource allows you to define tools and workflows directly in your Terraform configuration. This is ideal for custom tools, quick prototypes, and workflows that don't require a separate Git repository. For Git-based sources, use the `kubiya_source` resource instead.

<Tip>
Inline sources are perfect for custom automation that's tightly coupled with your infrastructure configuration, enabling rapid prototyping and deployment-specific tools.
</Tip>

## Container-First Architecture

Kubiya uses a container-first architecture where every tool is backed by a Docker image. This ensures:

- **Secure, isolated execution environments** - Each tool runs in its own container
- **Predictable and reproducible results** - Consistent execution across environments  
- **Language-agnostic tool implementation** - Support for any programming language
- **Easy integration with existing containerized workflows** - Leverage existing Docker images

## Prerequisites

Before using this resource, ensure you have:

1. A Kubiya account with API access
2. An API key (generated from Kubiya dashboard under Admin â†’ Kubiya API Keys)
3. Docker images accessible from your runner environment
4. Understanding of tool and workflow structure in Kubiya

## Quick Start

<CodeGroup>

```hcl Basic Inline Tool
resource "kubiya_inline_source" "hello_tool" {
  name   = "hello-world-tool"
  runner = "kubiya-hosted"
  
  tools = jsonencode([
    {
      name        = "say-hello"
      description = "A simple greeting tool"
      type        = "docker"
      image       = "alpine:latest"
      content     = "echo 'Hello, World!'"
    }
  ])
}

resource "kubiya_agent" "basic_agent" {
  name         = "greeting-agent"
  runner       = "kubiya-hosted"
  description  = "Agent with hello world tool"
  instructions = "You are a friendly agent that can greet users."
  
  sources = [kubiya_inline_source.hello_tool.id]
}
```

```hcl System Monitoring Tools
resource "kubiya_inline_source" "monitoring_tools" {
  name   = "system-monitoring-tools"
  runner = "kubiya-hosted"
  
  tools = jsonencode([
    {
      name        = "system-health-check"
      description = "Check system health metrics"
      type        = "docker"
      image       = "alpine:latest"
      content     = <<-BASH
        echo "=== System Health Check ==="
        echo "CPU Usage:"
        top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1
        echo ""
        echo "Memory Usage:"
        free -m | awk 'NR==2{printf "%.2f%%\n", $3*100/$2}'
        echo ""
        echo "Disk Usage:"
        df -h | grep -E '^/dev/' | awk '{print $1 " - " $5}'
      BASH
    }
  ])
}

resource "kubiya_agent" "monitoring_agent" {
  name         = "monitoring-specialist"
  runner       = "kubiya-hosted"
  description  = "System monitoring and diagnostics agent"
  instructions = "You are a monitoring specialist with tools for system health checks."
  
  sources = [kubiya_inline_source.monitoring_tools.id]
}
```

```hcl Python Analysis Tool
resource "kubiya_inline_source" "analysis_tools" {
  name   = "data-analysis-tools"
  runner = "kubiya-hosted"
  
  tools = jsonencode([
    {
      name        = "log-analyzer"
      description = "Analyze application logs for errors"
      type        = "docker"
      image       = "python:3.11-slim"
      with_files = [
        {
          destination = "/analyzer.py"
          content     = <<-PYTHON
            import re
            import sys
            from collections import Counter
            
            def analyze_logs(file_path):
                error_pattern = re.compile(r'(ERROR|CRITICAL|FATAL)', re.IGNORECASE)
                warn_pattern = re.compile(r'(WARNING|WARN)', re.IGNORECASE)
                
                errors = 0
                warnings = 0
                
                try:
                    with open(file_path, 'r') as f:
                        for line in f:
                            if error_pattern.search(line):
                                errors += 1
                            elif warn_pattern.search(line):
                                warnings += 1
                    
                    print(f"Log Analysis Results:")
                    print(f"Errors: {errors}")
                    print(f"Warnings: {warnings}")
                    print(f"Total Issues: {errors + warnings}")
                    
                except FileNotFoundError:
                    print(f"File not found: {file_path}")
                except Exception as e:
                    print(f"Error analyzing logs: {e}")
            
            if __name__ == "__main__":
                log_file = sys.argv[1] if len(sys.argv) > 1 else "/var/log/app.log"
                analyze_logs(log_file)
          PYTHON
        }
      ]
      content = "python /analyzer.py ${LOG_FILE}"
      args = [
        {
          name        = "LOG_FILE"
          type        = "string"
          description = "Path to log file to analyze"
          required    = false
          default     = "/var/log/app.log"
        }
      ]
    }
  ])
}
```

</CodeGroup>

## Configuration Examples

<Tabs>
  <Tab title="Deployment Workflows">
    Create automation workflows for deployment processes:

    ```hcl
    resource "kubiya_inline_source" "deployment_workflows" {
      name   = "deployment-automation"
      runner = "kubiya-hosted"
      
      workflows = jsonencode([
        {
          name        = "blue-green-deployment"
          description = "Blue-green deployment strategy"
          steps = [
            {
              name        = "validate-config"
              description = "Validate deployment configuration"
              executor = {
                type = "command"
                config = {
                  command = "kubectl apply --dry-run=client -f deployment.yaml"
                }
              }
            },
            {
              name        = "deploy-green"
              description = "Deploy green environment"
              depends     = ["validate-config"]
              executor = {
                type = "command"
                config = {
                  command = "kubectl apply -f green-deployment.yaml"
                }
              }
            },
            {
              name        = "health-check"
              description = "Check green environment health"
              depends     = ["deploy-green"]
              executor = {
                type = "command"
                config = {
                  command = "kubectl wait --for=condition=ready pod -l version=green --timeout=300s"
                }
              }
              output = "HEALTH_STATUS"
            },
            {
              name        = "switch-traffic"
              description = "Switch traffic to green"
              depends     = ["health-check"]
              executor = {
                type = "command"
                config = {
                  command = "kubectl patch service app -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'"
                }
              }
            }
          ]
        }
      ])
    }

    resource "kubiya_agent" "deployment_agent" {
      name         = "deployment-orchestrator"
      runner       = "kubiya-hosted"
      description  = "Deployment automation agent"
      instructions = "You orchestrate deployments using blue-green strategy."
      
      sources = [kubiya_inline_source.deployment_workflows.id]
    }
    ```
  </Tab>
  
  <Tab title="Data Processing Pipeline">
    Build ETL pipelines with data transformation:

    ```hcl
    resource "kubiya_inline_source" "data_pipeline" {
      name   = "data-processing-pipeline"
      runner = "kubiya-hosted"
      
      workflows = jsonencode([
        {
          name        = "etl-pipeline"
          description = "Extract, Transform, and Load data pipeline"
          steps = [
            {
              name        = "extract-data"
              description = "Extract data from source"
              executor = {
                type = "tool"
                config = {
                  tool_def = {
                    name        = "data-extractor"
                    description = "Extract data from API"
                    type        = "docker"
                    image       = "python:3.11-slim"
                    with_files = [
                      {
                        destination = "/extract.py"
                        content     = <<-PYTHON
                          import json
                          import random
                          
                          # Simulate data extraction
                          data = {
                              "records": [
                                  {"id": i, "value": random.randint(100, 1000)}
                                  for i in range(10)
                              ]
                          }
                          
                          print(json.dumps(data))
                        PYTHON
                      }
                    ]
                    content = "python /extract.py"
                  }
                }
              }
              output = "RAW_DATA"
            },
            {
              name        = "transform-data"
              description = "Transform extracted data"
              depends     = ["extract-data"]
              executor = {
                type = "tool"
                config = {
                  tool_def = {
                    name        = "data-transformer"
                    description = "Transform data"
                    type        = "docker"
                    image       = "python:3.11-slim"
                    with_files = [
                      {
                        destination = "/transform.py"
                        content     = <<-PYTHON
                          import os
                          import json
                          
                          raw_data = os.environ.get('data', '{}')
                          data = json.loads(raw_data)
                          
                          # Transform data
                          if 'records' in data:
                              for record in data['records']:
                                  record['transformed'] = True
                                  record['value_doubled'] = record.get('value', 0) * 2
                          
                          print(json.dumps(data))
                        PYTHON
                      }
                    ]
                    content = "python /transform.py"
                    args = [
                      {
                        name        = "data"
                        type        = "string"
                        description = "Raw data to transform"
                        required    = true
                      }
                    ]
                  }
                  args = {
                    data = "${RAW_DATA}"
                  }
                }
              }
              output = "TRANSFORMED_DATA"
            },
            {
              name        = "load-data"
              description = "Load data to destination"
              depends     = ["transform-data"]
              executor = {
                type = "agent"
                config = {
                  teammate_name = "data-loader"
                  message       = "Load the following data: ${TRANSFORMED_DATA}"
                }
              }
            }
          ]
        }
      ])
    }
    ```
  </Tab>
  
  <Tab title="API Testing Tools">
    Create tools for API testing and validation:

    ```hcl
    resource "kubiya_inline_source" "api_testing" {
      name   = "api-testing-tools"
      runner = "kubiya-hosted"
      
      tools = jsonencode([
        {
          name        = "api-health-check"
          description = "Check API endpoint health"
          type        = "docker"
          image       = "curlimages/curl:latest"
          content     = <<-BASH
            curl -s -o /dev/null -w "Status: %{http_code}\nResponse Time: %{time_total}s\n" ${API_URL}
          BASH
          args = [
            {
              name        = "API_URL"
              type        = "string"
              description = "API endpoint URL"
              required    = true
            }
          ]
        },
        {
          name        = "load-test"
          description = "Simple load testing"
          type        = "docker"
          image       = "alpine:latest"
          content     = <<-BASH
            apk add --no-cache curl
            
            echo "Starting load test..."
            for i in $(seq 1 ${REQUESTS}); do
              curl -s -o /dev/null -w "%{http_code} " ${API_URL}
            done
            echo ""
            echo "Load test completed: ${REQUESTS} requests sent"
          BASH
          args = [
            {
              name        = "API_URL"
              type        = "string"
              description = "API endpoint URL"
              required    = true
            },
            {
              name        = "REQUESTS"
              type        = "string"
              description = "Number of requests"
              required    = false
              default     = "10"
            }
          ]
        }
      ])
    }
    ```
  </Tab>
</Tabs>

## Advanced Configurations

<Accordion title="Mixed Tools and Workflows">
  Combine tools and workflows in one comprehensive source:

  ```hcl
  resource "kubiya_inline_source" "devops_toolkit" {
    name   = "complete-devops-toolkit"
    runner = "kubiya-hosted"
    
    tools = jsonencode([
      {
        name        = "k8s-diagnostics"
        description = "Kubernetes cluster diagnostics"
        type        = "docker"
        image       = "bitnami/kubectl:latest"
        content     = <<-BASH
          echo "=== Cluster Status ==="
          kubectl cluster-info
          echo ""
          echo "=== Node Status ==="
          kubectl get nodes
          echo ""
          echo "=== Pod Issues ==="
          kubectl get pods --all-namespaces | grep -v Running
        BASH
      },
      {
        name        = "docker-cleanup"
        description = "Clean up Docker resources"
        type        = "docker"
        image       = "docker:latest"
        content     = <<-BASH
          echo "Cleaning up Docker resources..."
          docker system prune -f
          docker image prune -a -f
          echo "Cleanup completed"
        BASH
      }
    ])
    
    workflows = jsonencode([
      {
        name        = "incident-response"
        description = "Automated incident response"
        steps = [
          {
            name = "diagnose"
            executor = {
              type = "tool"
              config = {
                tool_name = "k8s-diagnostics"
              }
            }
            output = "DIAGNOSIS"
          },
          {
            name    = "cleanup"
            depends = ["diagnose"]
            executor = {
              type = "tool"
              config = {
                tool_name = "docker-cleanup"
              }
            }
          },
          {
            name    = "notify"
            depends = ["cleanup"]
            executor = {
              type = "agent"
              config = {
                teammate_name = "slack-notifier"
                message       = "Incident resolved. Diagnosis: ${DIAGNOSIS}"
              }
            }
          }
        ]
      }
    ])
  }

  resource "kubiya_agent" "devops_agent" {
    name         = "devops-specialist"
    runner       = "kubiya-hosted"
    description  = "DevOps agent with tools and workflows"
    instructions = "You are a DevOps specialist with diagnostic tools and incident response workflows."
    
    sources = [kubiya_inline_source.devops_toolkit.id]
  }
  ```
</Accordion>

<Accordion title="Security Scanning Tools">
  Create security scanning and compliance tools:

  ```hcl
  resource "kubiya_inline_source" "security_tools" {
    name   = "security-scanning-tools"
    runner = "kubiya-hosted"
    
    tools = jsonencode([
      {
        name        = "dependency-check"
        description = "Check for vulnerable dependencies"
        type        = "docker"
        image       = "owasp/dependency-check:latest"
        content     = <<-BASH
          dependency-check.sh \
            --scan /src \
            --format JSON \
            --out /tmp/report.json \
            --suppression /tmp/suppressions.xml
          
          cat /tmp/report.json | jq '.dependencies[] | select(.vulnerabilities != null)'
        BASH
      },
      {
        name        = "secrets-scan"
        description = "Scan for exposed secrets"
        type        = "docker"
        image       = "trufflesecurity/trufflehog:latest"
        content     = <<-BASH
          trufflehog filesystem /src \
            --json \
            --only-verified
        BASH
      }
    ])
    
    workflows = jsonencode([
      {
        name        = "security-audit"
        description = "Complete security audit"
        steps = [
          {
            name = "scan-dependencies"
            executor = {
              type = "tool"
              config = {
                tool_name = "dependency-check"
              }
            }
            output = "DEPENDENCY_REPORT"
          },
          {
            name = "scan-secrets"
            executor = {
              type = "tool"
              config = {
                tool_name = "secrets-scan"
              }
            }
            output = "SECRETS_REPORT"
          },
          {
            name    = "generate-report"
            depends = ["scan-dependencies", "scan-secrets"]
            executor = {
              type = "agent"
              config = {
                teammate_name = "security-reporter"
                message       = "Generate security report from: Dependencies: ${DEPENDENCY_REPORT}, Secrets: ${SECRETS_REPORT}"
              }
            }
          }
        ]
      }
    ])
  }
  ```
</Accordion>

<Accordion title="Database Management Tools">
  Create database management and migration tools:

  ```hcl
  resource "kubiya_inline_source" "db_tools" {
    name   = "database-management-tools"
    runner = "kubiya-hosted"
    
    tools = jsonencode([
      {
        name        = "db-backup"
        description = "Backup PostgreSQL database"
        type        = "docker"
        image       = "postgres:15-alpine"
        content     = <<-BASH
          PGPASSWORD=${DB_PASSWORD} pg_dump \
            -h ${DB_HOST} \
            -U ${DB_USER} \
            -d ${DB_NAME} \
            > /backup/backup_$(date +%Y%m%d_%H%M%S).sql
          
          echo "Backup completed successfully"
        BASH
        args = [
          {
            name        = "DB_HOST"
            type        = "string"
            description = "Database host"
            required    = true
          },
          {
            name        = "DB_NAME"
            type        = "string"
            description = "Database name"
            required    = true
          },
          {
            name        = "DB_USER"
            type        = "string"
            description = "Database user"
            required    = true
          },
          {
            name        = "DB_PASSWORD"
            type        = "string"
            description = "Database password"
            required    = true
          }
        ]
      }
    ])
    
    workflows = jsonencode([
      {
        name        = "database-migration"
        description = "Database migration workflow"
        steps = [
          {
            name = "backup-current"
            executor = {
              type = "tool"
              config = {
                tool_name = "db-backup"
              }
            }
          },
          {
            name    = "run-migration"
            depends = ["backup-current"]
            executor = {
              type = "command"
              config = {
                command = "flyway migrate"
              }
            }
          },
          {
            name    = "verify-migration"
            depends = ["run-migration"]
            executor = {
              type = "command"
              config = {
                command = "flyway info"
              }
            }
          }
        ]
      }
    ])
  }
  ```
</Accordion>

## Arguments Reference

### Required Arguments

<ParamField path="name" type="string" required>
  The name of the inline source. Must be unique within your organization.
</ParamField>

### Optional Arguments

<ParamField path="runner" type="string" default="kubiya-hosted">
  The runner to use for executing tools and workflows from this source.
</ParamField>

<ParamField path="tools" type="string">
  JSON-encoded array of inline tool definitions. Each tool defines a containerized executable.
</ParamField>

<ParamField path="workflows" type="string">
  JSON-encoded array of workflow definitions. Each workflow defines a multi-step automation process.
</ParamField>

<ParamField path="dynamic_config" type="string">
  JSON-encoded configuration for dynamic parameters and source-level settings.
</ParamField>

## Tool Definition Structure

<ParamField path="tools[].name" type="string" required>
  Unique identifier for the tool.
</ParamField>

<ParamField path="tools[].description" type="string" required>
  Human-readable description of what the tool does.
</ParamField>

<ParamField path="tools[].type" type="string" required>
  Execution type (usually "docker" for containerized tools).
</ParamField>

<ParamField path="tools[].image" type="string" required>
  Docker image to use for tool execution.
</ParamField>

<ParamField path="tools[].content" type="string" required>
  Command or script to execute within the container.
</ParamField>

<ParamField path="tools[].with_files" type="array">
  Optional files to create in the container before execution:
  
  <ParamField path="tools[].with_files[].destination" type="string" required>
    File path within the container where the file should be created.
  </ParamField>
  
  <ParamField path="tools[].with_files[].content" type="string" required>
    Content of the file to be created.
  </ParamField>
</ParamField>

<ParamField path="tools[].args" type="array">
  Optional arguments that the tool accepts:
  
  <ParamField path="tools[].args[].name" type="string" required>
    Name of the argument (used as environment variable).
  </ParamField>
  
  <ParamField path="tools[].args[].type" type="string" required>
    Type of the argument (e.g., "string", "number", "boolean").
  </ParamField>
  
  <ParamField path="tools[].args[].description" type="string" required>
    Description of what the argument is used for.
  </ParamField>
  
  <ParamField path="tools[].args[].required" type="boolean" default="false">
    Whether the argument is required for tool execution.
  </ParamField>
  
  <ParamField path="tools[].args[].default" type="string">
    Default value for the argument if not provided.
  </ParamField>
</ParamField>

## Workflow Definition Structure

<ParamField path="workflows[].name" type="string" required>
  Name identifier for the workflow.
</ParamField>

<ParamField path="workflows[].description" type="string" required>
  Description of the workflow's purpose.
</ParamField>

<ParamField path="workflows[].steps" type="array" required>
  Array of workflow steps defining the execution sequence:
  
  <ParamField path="workflows[].steps[].name" type="string" required>
    Unique name for the step within the workflow.
  </ParamField>
  
  <ParamField path="workflows[].steps[].description" type="string">
    Optional description of what the step does.
  </ParamField>
  
  <ParamField path="workflows[].steps[].executor" type="object" required>
    Executor configuration defining how the step runs:
    - `type`: "tool", "command", or "agent"
    - `config`: Configuration specific to the executor type
  </ParamField>
  
  <ParamField path="workflows[].steps[].depends" type="array">
    Array of step names that must complete before this step runs.
  </ParamField>
  
  <ParamField path="workflows[].steps[].output" type="string">
    Variable name to store the step's output for use in subsequent steps.
  </ParamField>
</ParamField>

## Attributes Reference

In addition to all arguments above, the following attributes are exported:

<ParamField path="id" type="string">
  The unique identifier of the inline source.
</ParamField>

<ParamField path="type" type="string">
  The computed type of the source (always "inline").
</ParamField>

## Import

Inline sources can be imported using their ID:

<CodeGroup>

```bash Import Command
terraform import kubiya_inline_source.example <inline-source-id>
```

```hcl Import Block
import {
  to = kubiya_inline_source.example
  id = "<inline-source-id>"
}
```

</CodeGroup>

## Best Practices

<Card title="Container Management" icon="container">
  - Use specific image tags rather than "latest" for reproducibility
  - Choose lightweight base images when possible (alpine, slim variants)
  - Consider resource requirements when selecting Docker images
  - Ensure images are accessible from your runner environment
</Card>

<Card title="Security" icon="shield-halved">
  - Never hardcode credentials in tool definitions; use Kubiya secrets
  - Use read-only file systems where possible
  - Implement proper input validation in tool scripts
  - Audit tool permissions and capabilities regularly
</Card>

<Card title="Development & Testing" icon="flask">
  - Test tools and workflows in development before production use
  - Include error handling in tool scripts
  - Use echo statements and output variables for debugging workflows
  - Create focused, single-purpose tools that can be composed
</Card>

<Card title="Documentation & Maintenance" icon="book-open">
  - Include clear descriptions for tools and their parameters
  - Document expected inputs and outputs for each tool
  - Consider moving complex tools to Git repositories as they mature
  - Version control your Terraform configurations
</Card>

## Executor Types

<Tabs>
  <Tab title="Tool Executor">
    Execute custom tools defined in the same source:

    ```json
    {
      "type": "tool",
      "config": {
        "tool_name": "my-custom-tool",
        "args": {
          "param1": "value1",
          "param2": "value2"
        }
      }
    }
    ```
  </Tab>
  
  <Tab title="Command Executor">
    Execute shell commands directly:

    ```json
    {
      "type": "command",
      "config": {
        "command": "kubectl get pods --all-namespaces"
      }
    }
    ```
  </Tab>
  
  <Tab title="Agent Executor">
    Delegate tasks to other Kubiya agents:

    ```json
    {
      "type": "agent",
      "config": {
        "teammate_name": "notification-agent",
        "message": "Process completed with result: ${PREVIOUS_OUTPUT}"
      }
    }
    ```
  </Tab>
</Tabs>

## Compatibility

<Note>
**Requirements:**
- Kubiya Terraform Provider version >= 1.0.0
- Terraform >= 1.0
- Docker images must be accessible from the runner environment
- Tools and workflows are defined inline, not from Git repositories
</Note>

<Warning>
**Important Considerations:**
- Inline sources must be created before agents can reference them
- Large tool definitions may impact Terraform plan/apply performance
- Complex tools should consider migration to Git-based sources
- Container resource limits apply to tool execution
</Warning>

## Troubleshooting

<Accordion title="Tool Execution Issues">
  - Verify Docker images are accessible from the runner environment
  - Check tool arguments and environment variable formatting
  - Ensure file paths in with_files are absolute and valid
  - Review container logs for execution errors
</Accordion>

<Accordion title="Workflow Step Problems">
  - Validate step dependencies for circular references
  - Check output variable names match between steps
  - Ensure tool_name references match defined tool names
  - Verify executor configurations are properly formatted
</Accordion>

<Accordion title="JSON Encoding Issues">
  - Use jsonencode() function for complex structures
  - Validate JSON syntax with external tools if needed
  - Check for proper escaping of special characters
  - Ensure consistent indentation and formatting
</Accordion>